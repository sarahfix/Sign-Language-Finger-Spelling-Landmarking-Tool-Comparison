{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f811ab3",
   "metadata": {},
   "source": [
    "# Pose Estimation Tool Comparison\n",
    "\n",
    "This notebook runs multiple pose estimation tools (AlphaPose, OpenPose, YOLOv8, BlazePose) on frame sets and saves results to organized output directories.\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Before running, configure the following in the **Config** cell:\n",
    "- `FRAME_SET`: Which frame set to process (e.g., \"frames2\")\n",
    "- `OUTPUT_SUBDIR`: Output subdirectory number (e.g., \"2\")\n",
    "\n",
    "All outputs will be saved to `outputs/{tool_name}/{OUTPUT_SUBDIR}/`\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Run the **Imports** and **Config** cells first\n",
    "2. Run helper function cells (extract_frames, find_frames, ensure_out, etc.)\n",
    "3. Run cells for each tool you want to use\n",
    "4. Results are automatically saved to the configured output directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2d958",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66629e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import subprocess\n",
    "import shlex\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import re\n",
    "import itertools\n",
    "import csv\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1416c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c294d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\sarah\\OneDrive - Georgia Institute of Technology\\VIP\\landmarking\n"
     ]
    }
   ],
   "source": [
    "# Choose which frame set to use and output directory number\n",
    "FRAME_SET = \"frames2\"  # examples: \"frames1\", \"frames2\", \"frames3\", etc.\n",
    "OUTPUT_SUBDIR = \"2\"    # Output subdirectory number (change for different runs)\n",
    "\n",
    "# Directory setup\n",
    "ROOT = Path.cwd()\n",
    "FRAMES_DIR = ROOT / \"frames\"\n",
    "OUT_DIR = ROOT / \"outputs\"\n",
    "FRAMES_DIR.mkdir(exist_ok=True)\n",
    "OUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eddf533",
   "metadata": {},
   "source": [
    "## Getting Frames from Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff687ed",
   "metadata": {},
   "source": [
    "#### Splitting video into frames function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af983ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames=6, output_dir=FRAMES_DIR):\n",
    "    \"\"\"\n",
    "    Function created to extract evenly spaced frames from a video and save them as frame_01.jpg, frame_02.jpg, etc.\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        num_frames (int): Number of frames to extract.\n",
    "        output_dir (Path): Directory to save the extracted frames.\n",
    "    Returns:\n",
    "        tuple: (saved_paths, frame_indices) - list of saved frame paths and their indices\n",
    "    \"\"\"\n",
    "    if not Path(video_path).exists():\n",
    "        print(f\"Video file {video_path} does not exist.\")\n",
    "        return [], []\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "\n",
    "    if total_frames == 0:\n",
    "        cap.release()\n",
    "        return [], []\n",
    "    print(f\"Total frames in video: {total_frames}\")\n",
    "\n",
    "    # Choosing evenly spaced frame indices across the video timeline\n",
    "    indices = []\n",
    "    for k in range(num_frames):\n",
    "        start = int(total_frames * k / num_frames)\n",
    "        end = int(total_frames * (k + 1) / num_frames) - 1\n",
    "        if end < start:\n",
    "            idx = min(start, total_frames - 1)\n",
    "        else:\n",
    "            idx = random.randint(start, end)\n",
    "        indices.append(idx)\n",
    "\n",
    "    indices = sorted(indices)\n",
    "    print(\"Chosen frame indices:\", indices)\n",
    "\n",
    "    # Extract and save frames\n",
    "    saved_paths = []\n",
    "    for i, idx in enumerate(indices):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "                \n",
    "        # Save as frame_01.jpg, frame_02.jpg, etc.\n",
    "        output_file = output_path / f\"frame_{i+1:02d}.jpg\"\n",
    "        cv2.imwrite(str(output_file), frame)\n",
    "        saved_paths.append(output_file)\n",
    "        print(f\"Saved: {output_file} (from original frame {idx})\")\n",
    "\n",
    "    cap.release()\n",
    "    return saved_paths, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef73a71c",
   "metadata": {},
   "source": [
    "#### Extracting already split frames function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frames(frames_directory=\"frames/frames1\"):\n",
    "    \"\"\"\n",
    "    Function to find all frame images in the specified frames directory.\n",
    "    Args:\n",
    "        frames_directory (str): Path to the directory containing frame images\n",
    "    Returns:\n",
    "        tuple: (saved_paths, extracted_indices) - list of frame paths and their indices\n",
    "    \"\"\"\n",
    "    frames_dir = pathlib.Path(frames_directory)\n",
    "    saved_paths = sorted([f for f in frames_dir.glob(\"frame_*.jpg\")])\n",
    "    print(f\"Found existing frames in '{frames_directory}': {len(saved_paths)} frames\")\n",
    "    \n",
    "    extracted_indices = []\n",
    "    if saved_paths:\n",
    "        for path in saved_paths:\n",
    "            # Extract frame number from filename (e.g., \"frame_01.jpg\" = 1)\n",
    "            filename = path.stem # gets \"frame_01\" from \"frame_01.jpg\"\n",
    "            \n",
    "            # using regex to find all numbers in the filename\n",
    "            numbers = re.findall(r'\\d+', filename)\n",
    "            if numbers:\n",
    "                frame_number = int(numbers[-1])\n",
    "                extracted_indices.append(frame_number)\n",
    "    \n",
    "    return saved_paths, extracted_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6a5e2",
   "metadata": {},
   "source": [
    "#### Create frames or find existing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_paths, indices = extract_frames(\"videos/input3.mp4\", num_frames=6, output_dir=\"frames/frames3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac641707",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_paths, indices = find_frames(f\"frames/{FRAME_SET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e0a47",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_out(subdir_name, subdir_num=None):\n",
    "    \"\"\"\n",
    "    Ensure output directory exists and return path.\n",
    "    Args:\n",
    "        subdir_name (str): Name of the output subdirectory (e.g., \"blazepose_mediapipe\")\n",
    "        subdir_num (str, optional): Subdirectory number (e.g., \"2\"). If None, uses OUTPUT_SUBDIR from config.\n",
    "    Returns:\n",
    "        Path: Path to the output directory\n",
    "    \"\"\"\n",
    "    if subdir_num is None:\n",
    "        subdir_num = OUTPUT_SUBDIR\n",
    "    output_dir = pathlib.Path(\"outputs\") / subdir_name / subdir_num\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_keypoints_from_result(r):\n",
    "    \"\"\"\n",
    "    Extract keypoints from YOLOv8 pose results.\n",
    "    \n",
    "    Args:\n",
    "        r: YOLOv8 result object containing keypoints\n",
    "    Returns:\n",
    "        list: List of numpy arrays, each containing keypoints for one person\n",
    "              Shape: (num_persons, num_keypoints, 3) where 3 = (x, y, confidence)\n",
    "    Note:\n",
    "        YOLOv8 uses COCO format with 17 keypoints per person.\n",
    "    \"\"\"\n",
    "    persons = []\n",
    "    \n",
    "    # YOLOv8 pose results store keypoints in r.keypoints.data\n",
    "    if hasattr(r, 'keypoints') and r.keypoints is not None:\n",
    "        try:\n",
    "            kps_data = r.keypoints.data.cpu().numpy()\n",
    "            for person_idx in range(len(kps_data)):\n",
    "                person_kps = kps_data[person_idx]\n",
    "                persons.append(person_kps)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting keypoints: {e}\")\n",
    "    \n",
    "    return persons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ecc86d",
   "metadata": {},
   "source": [
    "## AlphaPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49260438",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_paths, extracted_indices = find_frames(f\"frames/{FRAME_SET}\")\n",
    "\n",
    "project_root = Path.cwd()\n",
    "alphapose_dir = project_root / \"alphapose\"\n",
    "demo_script = alphapose_dir / \"scripts\" / \"demo_api.py\"\n",
    "\n",
    "\n",
    "# Use the frames found by function\n",
    "selected_images = saved_paths[:6] # Should only be six anyway but grabs the first 6\n",
    "\n",
    "# Explicitly setting desired config and checkpoint paths (using relative paths)\n",
    "cfg_path = project_root / \"AlphaPose\" / \"configs\" / \"coco\" / \"resnet\" / \"256x192_res50_lr1e-3_1x.yaml\"\n",
    "checkpoint_path = project_root / \"AlphaPose\" / \"pretrained_models\" / \"fast_res50_256x192.pth\"\n",
    "\n",
    "gpus = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48766175",
   "metadata": {},
   "source": [
    "### Run Alphapose (1 image at a time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discovery variables should already exist from earlier cell\n",
    "try:\n",
    "    demo_script, cfg_path, checkpoint_path, selected_images\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Run the discovery cell first so demo_script, cfg_path, checkpoint_path and selected_images exist.\")\n",
    "\n",
    "alphapose_root = Path(demo_script).parents[1]\n",
    "\n",
    "cfg_path = alphapose_root / \"configs\" / \"coco\" / \"resnet\" / \"256x192_res50_lr1e-3_1x.yaml\"\n",
    "\n",
    "if not cfg_path.exists():\n",
    "    raise FileNotFoundError(f\"Config does not exist at {cfg_path}\")\n",
    "\n",
    "overlay_dir = alphapose_root / \"examples\" / \"res\" / \"vis\"\n",
    "overlay_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "env = os.environ.copy()\n",
    "cur_pythonpath = env.get(\"PYTHONPATH\",\"\")\n",
    "alphapose_abs = str(alphapose_root.resolve())\n",
    "if alphapose_abs not in cur_pythonpath.split(os.pathsep):\n",
    "    env[\"PYTHONPATH\"] = alphapose_abs + (os.pathsep + cur_pythonpath if cur_pythonpath else \"\")\n",
    "\n",
    "python_exec = sys.executable\n",
    "base_args = [\n",
    "    python_exec,\n",
    "    str(demo_script),\n",
    "    \"--cfg\", str(cfg_path),\n",
    "    \"--checkpoint\", str(checkpoint_path),\n",
    "    \"--save_img\",\n",
    "    \"--format\", \"coco\",\n",
    "    \"--gpus\", \"-1\"\n",
    "]\n",
    "\n",
    "# Run AlphaPose on just one image\n",
    "img_path = selected_images[1]\n",
    "cmd = base_args + [\"--image\", str(img_path.resolve())]\n",
    "\n",
    "start = time.time()\n",
    "try:\n",
    "    proc = subprocess.run(cmd, env=env, cwd=str(alphapose_root), capture_output=True, text=True, timeout=900)\n",
    "    elapsed = time.time() - start\n",
    "    rc = proc.returncode\n",
    "    \n",
    "    if rc != 0:\n",
    "        print(f\"Failed with return code: {rc}\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"Timeout for image\", img_path)\n",
    "except Exception as e:\n",
    "    print(\"Exception for image\", img_path, \":\", repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f292d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd()\n",
    "alphapose_root = Path(demo_script).parents[1]\n",
    "intermediate_output_dir = alphapose_root / \"examples\" / \"res\"\n",
    "overlay_dir = intermediate_output_dir / \"vis\"\n",
    "\n",
    "final_output_dir = project_root / \"outputs\" / \"alphapose\" / OUTPUT_SUBDIR\n",
    "final_overlays = final_output_dir / \"overlays\"\n",
    "final_json = final_output_dir / \"json\"\n",
    "\n",
    "final_overlays.mkdir(parents=True, exist_ok=True)\n",
    "final_json.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "original_image_name = selected_images[1].stem\n",
    "\n",
    "if overlay_dir.exists():\n",
    "    # Look for overlay image with the same base name\n",
    "    for f in sorted(overlay_dir.glob(\"*\")):\n",
    "        if f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"] and original_image_name in f.stem:\n",
    "            dst = final_overlays / \"02_result.jpg\"\n",
    "            shutil.copy2(f, dst)\n",
    "            break\n",
    "\n",
    "json_sources = [\n",
    "    intermediate_output_dir / \"alphapose-results.json\",\n",
    "    alphapose_root / \"alphapose-results.json\"\n",
    "]\n",
    "\n",
    "for json_source in json_sources:\n",
    "    if json_source.exists():\n",
    "        dst = final_json / \"02_result.json\"\n",
    "        shutil.copy2(json_source, dst)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4005bfaa",
   "metadata": {},
   "source": [
    "## BlazePose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc229f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_paths, extracted_indices = find_frames(f\"frames/{FRAME_SET}\")\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "blazepose_out = ensure_out(\"blazepose_mediapipe\")\n",
    "json_data = defaultdict(list)\n",
    "\n",
    "with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3) as pose:\n",
    "    for fp in saved_paths:\n",
    "        img = cv2.imread(str(fp))\n",
    "        h, w = img.shape[:2]\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(img_rgb)\n",
    "        vis = img.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            # Convert landmarks to the desired format\n",
    "            keypoints = []\n",
    "            total_score = 0.0\n",
    "            \n",
    "            for idx, lm in enumerate(results.pose_landmarks.landmark):\n",
    "                x = lm.x * w\n",
    "                y = lm.y * h\n",
    "                visibility = lm.visibility\n",
    "                \n",
    "                # Add to keypoints list in the format: [x, y, score]\n",
    "                keypoints.extend([float(x), float(y), float(visibility)])\n",
    "                total_score += visibility\n",
    "            \n",
    "            # Calculate average score for this detection\n",
    "            avg_score = total_score / len(results.pose_landmarks.landmark) if results.pose_landmarks.landmark else 0\n",
    "            \n",
    "            json_data[str(fp)].append({\n",
    "                \"score\": float(avg_score),\n",
    "                \"keypoints\": keypoints\n",
    "            })\n",
    "            \n",
    "            for idx, lm in enumerate(results.pose_landmarks.landmark):\n",
    "                x = int(lm.x * w)\n",
    "                y = int(lm.y * h)\n",
    "                vis = cv2.circle(vis, (x, y), 3, (0, 255, 0), -1)\n",
    "        \n",
    "        # Save visualization\n",
    "        outimg = blazepose_out / f\"{fp.stem}_blazepose.jpg\"\n",
    "        cv2.imwrite(str(outimg), vis)\n",
    "\n",
    "# Save JSON\n",
    "json_path = blazepose_out / \"blazepose_landmarks.json\"\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(dict(json_data), f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd45338",
   "metadata": {},
   "source": [
    "## OpenPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function for the configured frame set\n",
    "frames_directory = f\"frames/{FRAME_SET}\"\n",
    "saved_paths, extracted_indices = find_frames(frames_directory)\n",
    "\n",
    "project_root = Path.cwd()\n",
    "\n",
    "frames_dir_absolute = (project_root / frames_directory).resolve()\n",
    "\n",
    "try:\n",
    "    openpose_bin\n",
    "except NameError:\n",
    "    openpose_bin = project_root / \"openpose\" / \"bin\" / \"OpenPoseDemo.exe\"\n",
    "\n",
    "if not openpose_bin.exists():\n",
    "    raise FileNotFoundError(f\"OpenPose binary not found at {openpose_bin}\")\n",
    "\n",
    "final_output_dir = project_root / \"outputs\" / \"openpose\" / OUTPUT_SUBDIR\n",
    "final_overlays = final_output_dir / \"overlays\"\n",
    "final_json = final_output_dir / \"json\"\n",
    "final_overlays.mkdir(parents=True, exist_ok=True)\n",
    "final_json.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "openpose_root_guess = openpose_bin.parents[1]\n",
    "models_dir = openpose_root_guess / \"models\"\n",
    "\n",
    "if not models_dir.exists():\n",
    "    # Try alternative location\n",
    "    models_dir = project_root / \"openpose\" / \"models\"\n",
    "    if not models_dir.exists():\n",
    "        raise FileNotFoundError(f\"Models directory not found at {models_dir}\")\n",
    "\n",
    "cmd = [\n",
    "    str(openpose_bin),\n",
    "    \"--image_dir\", str(frames_dir_absolute),\n",
    "    \"--write_images\", str(final_overlays),\n",
    "    \"--write_json\", str(final_json),\n",
    "    \"--model_folder\", str(models_dir),\n",
    "    \"--hand\",\n",
    "    \"--face\"\n",
    "]\n",
    "\n",
    "\n",
    "# Run OpenPose\n",
    "try:\n",
    "    proc = subprocess.run(cmd, cwd=str(openpose_bin.parent), capture_output=True, text=True)\n",
    "    \n",
    "    if proc.returncode != 0:\n",
    "        print(f\"OpenPose failed with return code: {proc.returncode}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Exception when running OpenPose:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8850b95",
   "metadata": {},
   "source": [
    "## Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f911a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function for the configured frame set\n",
    "frames_directory = f\"frames/{FRAME_SET}\"\n",
    "saved_paths, extracted_indices = find_frames(frames_directory)\n",
    "\n",
    "yolo_out = ensure_out(\"yolov8\")\n",
    "\n",
    "MODEL_NAME = \"yolov8n-pose.pt\"\n",
    "model = YOLO(MODEL_NAME)\n",
    "\n",
    "for fp in saved_paths:\n",
    "    img = cv2.imread(str(fp))\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    \n",
    "    # Predict with YOLOv8 pose\n",
    "    results = model.predict(source=str(fp), save=False, verbose=False)\n",
    "    \n",
    "    # Create JSON data for this frame\n",
    "    frame_json_data = {\n",
    "        \"version\": 1.3,\n",
    "        \"people\": []\n",
    "    }\n",
    "    \n",
    "    for result_idx, r in enumerate(results):\n",
    "        vis = img.copy()\n",
    "        \n",
    "        person_kps_list = parse_keypoints_from_result(r)\n",
    "        \n",
    "        for pid, person_kps in enumerate(person_kps_list):\n",
    "            pose_keypoints_2d = []\n",
    "            for kp in person_kps:\n",
    "                x, y, confidence = float(kp[0]), float(kp[1]), float(kp[2])\n",
    "                pose_keypoints_2d.extend([x, y, confidence])\n",
    "            \n",
    "            # Create person data structure\n",
    "            person_data = {\n",
    "                \"person_id\": [pid],\n",
    "                \"pose_keypoints_2d\": pose_keypoints_2d,\n",
    "                \"face_keypoints_2d\": [0] * 210,\n",
    "                \"hand_left_keypoints_2d\": [0] * 63,\n",
    "                \"hand_right_keypoints_2d\": [0] * 63,\n",
    "                \"pose_keypoints_3d\": [],\n",
    "                \"face_keypoints_3d\": [],\n",
    "                \"hand_left_keypoints_3d\": [],\n",
    "                \"hand_right_keypoints_3d\": []\n",
    "            }\n",
    "            \n",
    "            frame_json_data[\"people\"].append(person_data)\n",
    "            \n",
    "            # Draw keypoints for visualization\n",
    "            for kp_idx, kp in enumerate(person_kps):\n",
    "                x, y, confidence = float(kp[0]), float(kp[1]), float(kp[2])\n",
    "                \n",
    "                if confidence > 0.1:\n",
    "                    x_pixel = int(round(x))\n",
    "                    y_pixel = int(round(y))\n",
    "                    \n",
    "                    if 0 <= x_pixel < img_width and 0 <= y_pixel < img_height:\n",
    "                        color = (0, 255, 0)\n",
    "                        cv2.circle(vis, (x_pixel, y_pixel), 4, color, -1)\n",
    "                        cv2.circle(vis, (x_pixel, y_pixel), 6, (255, 255, 255), 1)\n",
    "                        cv2.putText(vis, str(kp_idx), (x_pixel+5, y_pixel-5), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        # Save visualization\n",
    "        outimg = yolo_out / f\"{fp.stem}_yolo.jpg\"\n",
    "        cv2.imwrite(str(outimg), vis)\n",
    "        \n",
    "        json_path = yolo_out / f\"{fp.stem}_keypoints.json\"\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(frame_json_data, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
